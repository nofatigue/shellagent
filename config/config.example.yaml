openrouter:
  # Get your API key from https://platform.openai.com/api-keys or https://console.anthropic.com/
  # Or use environment variable: export SHELLAGENT_API_KEY="your-key"
  api_key: ${SHELLAGENT_API_KEY}
  
  # Provider: openai, claude, or ollama
  provider: openai
  
  # Model to use
  # OpenAI: gpt-4o-mini, gpt-4o, gpt-3.5-turbo
  # Claude: claude-3-haiku-20240307, claude-3-sonnet-20240229, claude-3-opus-20240229
  # Ollama: llama2, codellama, mistral (any model you have pulled)
  model: "gpt-4o-mini"
  
  # API base URL (adjust for different providers)
  # OpenAI: https://api.openai.com/v1
  # OpenRouter: https://openrouter.ai/api/v1
  # Ollama: http://localhost:11434
  base_url: "https://api.openai.com/v1"

daemon:
  host: "localhost"
  port: 5738

preferences:
  # Whether to automatically execute commands (not recommended)
  auto_execute: false
  
  # Include context (cwd, shell, OS) in prompts
  context_aware: true
  
  # Include explanation with commands
  explain_commands: true
  
  # Maximum tokens for LLM response
  max_tokens: 500
